{
  "metadata": {
    "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": { "name": "ipython", "version": 3 },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31234,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# CLIP fine-tuning for Egyptian dishes (Kaggle)\n\nThis notebook is designed to run in **Kaggle** after you push your repo to **GitHub**.\n\nWhat it does:\n1. Clone your GitHub repo\n2. Install dependencies\n3. Run sanity checks (GPU, dataset path, folder-per-class layout)\n4. Train **frozen OpenCLIP + linear head**\n5. Evaluate **trained head** + **zero-shot baseline**\n6. Zip `artifacts/` for download\n\n> Kaggle settings:\n> - Turn **GPU** ON\n> - Turn **Internet** ON (needed for `git clone` + pip)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 0) Set your GitHub repo\n\nReplace `GITHUB_REPO` with your repository HTTPS URL.\n\nIf your training script lives in a subfolder, set `PROJECT_SUBDIR`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "GITHUB_REPO = \"https://github.com/<YOUR_USERNAME>/<YOUR_REPO>.git\"\nBRANCH = \"main\"\nREPO_DIR = \"repo\"\n\n# If your script is inside a subfolder (e.g. \"clip_finetune\"), set it here.\n# Leave as \"\" if you run from repo root.\nPROJECT_SUBDIR = \"\"  # example: \"clip_finetune\"\n",
      "metadata": { "trusted": true },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 1) Clone repo",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!rm -rf {REPO_DIR}\n!git clone --depth 1 --branch {BRANCH} {GITHUB_REPO} {REPO_DIR}\n\n%cd {REPO_DIR}\n\nimport os, sys\nif PROJECT_SUBDIR:\n    os.chdir(PROJECT_SUBDIR)\n    print(\"Changed directory to:\", os.getcwd())\n\n# Make current project directory importable\nsys.path.append(os.getcwd())\nprint(\"PYTHONPATH +:\", os.getcwd())\n",
      "metadata": { "trusted": true },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 2) Install dependencies\n\nIf `requirements.txt` exists in the current directory, this installs it.\nOtherwise installs minimal deps for OpenCLIP fine-tuning.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import os\n\nif os.path.exists(\"requirements.txt\"):\n    !pip -q install -r requirements.txt\nelse:\n    !pip -q install open_clip_torch torch torchvision pillow numpy tqdm\n\nprint(\"Done installing dependencies\")\n",
      "metadata": { "trusted": true },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 3) Sanity checks\n\nThis checks:\n- GPU availability\n- Torch/CUDA versions\n- Dataset path exists\n- Dataset layout is folder-per-class\n- Total image count\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pathlib import Path\nimport torch\n\nprint(\"cwd:\", Path.cwd())\nprint(\"torch:\", torch.__version__)\nprint(\"cuda available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"cuda device:\", torch.cuda.get_device_name(0))\n\n# TODO: set this to your Kaggle dataset folder.\n# It MUST contain subfolders = class names.\nDATA_ROOT = \"/kaggle/input/<YOUR_DATASET_NAME>/Egyptian\"\n\nroot = Path(DATA_ROOT)\nprint(\"DATA_ROOT:\", root)\nprint(\"exists:\", root.exists())\n\nif not root.exists():\n    raise FileNotFoundError(\"DATA_ROOT does not exist. Update DATA_ROOT.\")\n\nclass_dirs = [p.name for p in root.iterdir() if p.is_dir()]\nclass_dirs.sort()\nprint(\"num classes:\", len(class_dirs))\nprint(\"sample classes:\", class_dirs[:20])\n\nexts = {\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\"}\nnum_imgs = sum(1 for p in root.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts)\nprint(\"total images:\", num_imgs)\n\nif len(class_dirs) == 0:\n    raise ValueError(\"No class folders found. Expected folder-per-class dataset.\")\nif num_imgs == 0:\n    raise ValueError(\"No images found under DATA_ROOT.\")\n",
      "metadata": { "trusted": true },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 4) Train + Evaluate (single script)\n\nThis runs your script (with tqdm logging).\n\nOutputs:\n- `artifacts/ckpts/egypt_clip_linear.pt`\n- `artifacts/reports/metrics.json`\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import os, sys, subprocess\nfrom pathlib import Path\n\n# Adjust if you placed the script elsewhere.\nSCRIPT = Path(\"clip_finetune/scripts/train_eval_clip_linear.py\")\nif not SCRIPT.exists():\n    SCRIPT = Path(\"scripts/train_eval_clip_linear.py\")\n\nif not SCRIPT.exists():\n    raise FileNotFoundError(\"Could not find train_eval_clip_linear.py. Update SCRIPT path in this cell.\")\n\nenv = os.environ.copy()\nenv[\"PYTHONPATH\"] = str(Path(\".\").resolve())\n\ncmd = [\n    sys.executable, str(SCRIPT),\n    \"--data_root\", DATA_ROOT,\n    \"--device\", \"cuda\",\n    \"--use_amp\",\n    \"--epochs\", \"10\",\n    \"--batch_size\", \"64\",\n    \"--num_workers\", \"2\",\n    \"--model_name\", \"ViT-B-32-quickgelu\",\n    \"--pretrained\", \"openai\",\n]\n\nprint(\"Running:\\n\", \" \".join(cmd))\nsubprocess.check_call(cmd, env=env)\n",
      "metadata": { "trusted": true },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 5) View metrics",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import json\nfrom pathlib import Path\n\nmetrics_path = Path(\"artifacts/reports/metrics.json\")\nprint(\"metrics_path:\", metrics_path.resolve())\nprint(\"exists:\", metrics_path.exists())\n\nif metrics_path.exists():\n    metrics = json.loads(metrics_path.read_text(encoding=\"utf-8\"))\n    metrics\n",
      "metadata": { "trusted": true },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 6) Zip artifacts for download\n\nAfter this cell, the zip will appear in Kaggle's **Output** panel.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!ls -la artifacts || true\n!zip -r artifacts.zip artifacts || true\n!ls -la artifacts.zip || true\n",
      "metadata": { "trusted": true },
      "outputs": [],
      "execution_count": null
    }
  ]
}
